---
jupytext:
  cell_metadata_json: true
  formats: ipynb,md:myst
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.16.4
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---



+++

# Which model should we deploy?


Here, we use the `ucimlrepo` library to load a dataset. 

```{code-cell} ipython3

from ucimlrepo import fetch_ucirepo 
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import pandas as pd
from sklearn import datasets
from sklearn import cluster
from sklearn import svm
from sklearn import tree
# import the whole model selection module
from sklearn import model_selection
from myst_nb import glue
from IPython.display import Markdown
sns.set_theme(palette='colorblind')
  
# fetch dataset 
phishing_websites = fetch_ucirepo(id=327) 
  
```

First, let's learn about the data a little:


```{code-cell} ipython3
:tags: ["hide-input"]
# metadata was a dictionary, so I put it in a df to make it easier to read
md_meta = ''
for section, value in phishing_websites.metadata.items():
    md_meta += '### ' + section.title()
    md_meta += '\n\n' +  str(value) +  '\n\n'

Markdown(md_meta)
```

```{code-cell} ipython3
# variable information 
print(phishing_websites.variables) 
```

Next, we can pull out the features and targets:

```{code-cell} ipython3


# data (as pandas dataframes) 
phishing_X = phishing_websites.data.features[:500]
phishing_y = phishing_websites.data.targets [:500]
```

```{code-cell} ipython3


rows,cols = phishing_X.shape

glue("num_rows", rows, display=False)
glue("num_cols",cols, display=False)
```

we imported only {glue:}`num_rows` rows of the data which has {glue:}`num_cols` variables

+++

Now the target

```{code-cell} ipython3
phishing_y.shape
```

```{code-cell} ipython3


phishing_X.head()
```

Now we can split into train and test data

```{code-cell} ipython3


phishing_X_train, phishing_X_test, phishing_y_train, phishing_y_test = model_selection.train_test_split(
  phishing_X,phishing_y, test_size =.2)
```

and then we can fit and optimize models

```{code-cell} ipython3


# create dt,
dt = tree.DecisionTreeClassifier()

# set param grid 
params_dt = {'criterion':['gini','entropy'],
       'max_depth':list(range(4,45,3)),
    'min_samples_leaf':list(range(2,20,2))}
# create optimizer
dt_opt = model_selection.GridSearchCV(dt,params_dt,cv=10)


# optimize the dt parameters
dt_opt.fit(phishing_X_train,phishing_y_train)

# store the results in a dataframe
dt_df = pd.DataFrame(dt_opt.cv_results_)


# create svm, its parameter grid and optimizer
svm_clf = svm.SVC()
param_grid = {'kernel':['linear','rbf'], 'C':[.5, .75,1,2,5,7, 10]}
svm_opt = model_selection.GridSearchCV(svm_clf,param_grid,cv=10)

# optmize the svm put the CV results in a dataframe
svm_opt.fit(phishing_X_train,phishing_y_train)
sv_df = pd.DataFrame(svm_opt.cv_results_)
```

and then we can start to design our comparison analysis.

## Overall Performance

```{code-cell} ipython3


acc_dt = dt_opt.score(phishing_X_test,phishing_y_test) *100
acc_sv = svm_opt.score(phishing_X_test,phishing_y_test) *100

two_scores = pd.Series({'decision tree':acc_dt,
              'support vector machine':acc_sv})

winner = two_scores.idxmin()

glue("dt_test", acc_dt, display=False)
glue("sv_test", acc_sv, display=False)
glue("best_model", winner, display=False)
```

The deciions tree test score was: {glue:}`dt_test` and the SVM test score was {glue:}`sv_test`, so on performance alone, {glue:}`best_model` is the better one. 

## Reliability

```{code-cell} ipython3

dt_df.loc[dt_opt.best_index_]
```

```{code-cell} ipython3
dt_df['mean_test_score'].describe()
```

:::{note}
we discussed the ways to compare a model further, mostly reviewing and reinforcing what was covered in the last class
:::

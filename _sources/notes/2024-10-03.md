---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.16.4
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---


# Merging Data & Databases


## Merging Data 

```{code-cell} ipython3
import pandas as pd
import sqlite3
from urllib import request
```

we're going to work with a set of datasets today that are stored in a repo.
```{code-cell} ipython3
course_data_url = 'https://raw.githubusercontent.com/rhodyprog4ds/rhodyds/main/data/'
```


 We can load in two data sets of NBA player information.

```{code-cell} ipython3
df_18 = pd.read_csv(course_data_url+'2018-players.csv')
df_19 = pd.read_csv(course_data_url+'2019-players.csv')
```
and take a peek at each
```{code-cell} ipython3
df_18.head()
```

```{code-cell} ipython3
df_19.head()
```
```{important}
Remember `shape` is a property, not a method, so it does not need `()`
```

Let's make note of the shape of each
```{code-cell} ipython3
df_18.shape, df_19.shape
```

**this created a tuple**

### What if we want to analyze them together?

We can stack them, but this does not make it easy to see , for example, who changed teams. 
```{code-cell} ipython3
pd.concat([df_18,df_19])
```


```{code-cell} ipython3
pd.concat([df_18,df_19]).shape
```


we can see that this is the total number of rows:
```{code-cell} ipython3
748+626
```


Note that this has the maximum number of columns (because both had some overlapping
  columns) and the total number of rows.



### How can we find which players changed teams?

To do this we want to have one player column and a column with each year's team.

We can use a merge to do that.


```{code-cell} ipython3
pd.merge(df_18,df_19).head(2)
```


if we merge them without any parameters, it tries to merge on all shared columns.  We want to merge them using the `PLAYER_ID` column though, we would say that we are "merging on player ID" and we use the `on` parameter to do it.  In this case, it looks for the values in the `PLAYER_ID` column that appear in both DataFrames and combines them into a single row. 

```{code-cell} ipython3
pd.merge(df_18,df_19,on='PLAYER_ID',suffixes=('_18','_19')).head(2)
```


Since there are other columns that appear in both DataFrames, they get a suffix, which by default is `x` or `y`, we can specify them though.


```{code-cell} ipython3
pd.merge(df_18,df_19,on='PLAYER_ID',suffixes=('_18','_19')).shape
```



### Which players played in 2018, but not 2019?

We have different types of merges, inner is both, out is either.  Left and right keep all the rows of one dataFrame.  We can use left with `df_18` as the left DataFrame to see which players played only in 18.


```{code-cell} ipython3
pd.merge(df_18,df_19,on='PLAYER_ID',how='left',suffixes=('_18','_19')).shape
```

```{code-cell} ipython3
pd.merge(df_18,df_19,on='PLAYER_ID',how='left',suffixes=('_18','_19')).info()
```
IF we save this to a variable, we can answer our question

```{code-cell} ipython3
df_18_only = pd.merge(df_18,df_19,on='PLAYER_ID',suffixes=('_18','_19'),how='left')
df_18_only.head(2)
```



```{code-cell} ipython3
len(df_18_only[df_18_only['TEAM_ID_19'].isna()]['PLAYER_ID'].unique())
```

Also, note that this has different types than before.  There are some players who only played one season, so they have a NaN value in some colums. pandas always casts a whole column. 


## Getting Data from Databases


### What is a Database?


A common attitude in Data Science is:

> If your data fits in memory there is no advantage to putting it in a database: it will only be slower and more frustrating.     â€”[ Hadley Wickham](https://dbplyr.tidyverse.org/articles/dbplyr.html)


Businesses and research organizations nearly always have too much data to feasibly work without a database.
Instead, they use different tools which are designed to scale to very large amounts of data. These tools are largely databases like Snowflake or Google's BigQuery and distributed computing frameworks like Apache Spark.


```{warning}
We are going to focus on the case of getting data out of a Database so that you
can use it and making sure you know what a Database is.  


You could spend a whole semester on databases:
- CSC436 covers how to implement them in detail (recommended, but requires CSC212)
- BAI456 only how to use them (counts for DS majors, but if you want to
      understand them deeper, the CSC one is recommended)

```

For the purpose of this class the key attributes of a database are:
- it is a collection of tables
- the data is accessed live from disk (not RAM)
- you send a query to the database to get the data (or your answer)


Databases can be designed in many different ways.  For examples two popular ones.

- [SQLite](https://www.sqlite.org/index.html) is optimized for transactional workloads, which means a high volume of requests that involving inserting or reading a couple things. This is good for eg a webserver.
- [DuckDB](https://duckdb.org/) is optimized for analytical workloads, which means a small number of requests that each require reading many records in the database. This is better for eg: data science

**Experimenting with [DuckDB](https://duckdb.org/docs/guides/python/install) is a way to earn construct level 3**


### Accessing a Database from Python

We will use pandas again, as well as the `request` module from the `urllib`
package and `sqlite3`.

Off the shelf, pandas cannot read databased by default. We'll use the
[`sqlite3`](https://docs.python.org/3/library/sqlite3.html) library, but there
are others, depending on the type of database.

First we need to download the database to work with it.

```{code-cell} ipython3
request.urlretrieve('https://github.com/rhodyprog4ds/rhodyds/raw/main/data/nba1819.db',
      'nba1819.db')
```

Next, we set up a connection, that links the the notebook to the database.
 To use it, we add a cursor.

```{code-cell} ipython3
conn = sqlite3.connect('nba1819.db')
cursor = conn.cursor()
```

We can use execute to pass SQL queries through the cursor to the database.

```{code-cell} ipython3
cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
```

Then we use `fetchall` to get the the results of the query.

```{code-cell} ipython3
cursor.fetchall()
```


If we fetch again, there is nothing to fetch.  Fetch pulls what was queued by
execute.
```{code-cell} ipython3
cursor.fetchall()
```


```{code-cell} ipython3
pd.read_sql("SELECT name FROM sqlite_master WHERE type='table';",conn)
```



## Querying with pandas

We can use `pd.read_sql` to send queries, get the result sand transform them
into a DataFrame all at once

We can pass the exact same queries if we want. 


```{code-cell} ipython3
pd.read_sql("SELECT name FROM sqlite_master WHERE type='table';",conn)
```

or we can get all of one of the tables: 

```{code-cell} ipython3
pd.read_sql('SELECT * FROM teams',conn).head(1)
```


### Which player was traded the most during the 2018 season? How many times?  


There is one row in players per team a played for per season, so if a
player was traded (changed teams), they are in there multiple times.

First, we'll check the column names
```{code-cell} ipython3
pd.read_sql("SELECT * FROM playerTeams2018 LIMIT 1",conn)
```

then get the 2018 players, we only need the `PLAYER_ID` column for this question
```{code-cell} ipython3
p18 =pd.read_sql("SELECT PLAYER_ID FROM playerTeams2018 ",conn)
```

Then we can use value counts

```{code-cell} ipython3
p18.value_counts().sort_values(ascending=False).head(10)
```

and we can get the player's name from the player name **remember our first query told us all the tables**

```{code-cell} ipython3
pd.read_sql("SELECT PLAYER_NAME FROM playerNames WHERE PLAYER_ID = 1629150",conn)
```


### Did more players who changed teams from the 2018 season to the 2019 season stay in the same conferences or switch conferences?

In the NBA, there are 30 teams organized into two conferences: East and West;
the `conferences` table has the columns `TEAM_ID` and `CONFERENCE`

Let's build a Dataframe that could answer the question. 

I first pulled 1 row from each table I needed to see the columns. 
```{code-cell} ipython3
pd.read_sql('SELECT * FROM conferences LIMIT 1',conn)
```

```{code-cell} ipython3
pd.read_sql('SELECT * FROM playerTeams2018 LIMIT 1',conn)
```

```{code-cell} ipython3
pd.read_sql('SELECT * FROM playerTeams2019 LIMIT 1',conn)
```


Then I pulled the columns I needed from each of the 3 tables into a separate DataFrame.
`````{margin}
```{note}
You can do the merging in SQL and pull only the merged table technically, but I use pandas more than sql so I did the minimum in SQL and the rest in pandas.  
```
`````

```{code-cell} ipython3
conf_df = pd.read_sql('SELECT TEAM_ID,CONFERENCE FROM conferences',conn)
df18 = pd.read_sql('SELECT TEAM_ID,PLAYER_ID FROM playerTeams2018',conn)
df19 = pd.read_sql('SELECT TEAM_ID,PLAYER_ID FROM playerTeams2019',conn)
df18_c = pd.merge(df18,conf_df,on='TEAM_ID')
df19_c = pd.merge(df19,conf_df,on='TEAM_ID')
df1819_conf = pd.merge(df18_c,df19_c, on='PLAYER_ID',suffixes=('_2018','_2019'))
df1819_conf
```

Then I merged the conference with each set of player informationon the teams. Then I merged the two expanded single year DataFrames together. 

Now, to answer the question, we have a bit more work to do.  I'm going to use a `lambda` and `apply` to make a column that says same or new for the relative conference of the two seasons. 

```{code-cell} ipython3
labels = {False:'new',True:'same'}
change_conf = lambda row: labels[row['CONFERENCE_2018']==row['CONFERENCE_2019']]
df1819_conf['conference_1819']= df1819_conf.apply(change_conf,axis=1)
df1819_conf.head()
```

Then I can use this DataFrame grouped by my new column to get the unique players in each situation new or same conference. 
```{code-cell} ipython3
df1819_conf.groupby('conference_1819')['PLAYER_ID'].apply(pd.unique)
```

And finally, get the length of each of those lists. 
```{code-cell} ipython3
df1819_conf.groupby('conference_1819')['PLAYER_ID'].apply(pd.unique).apply(len)
```

This, however, includes players who stayed on the same team, so we also need to split for who changed teams. First we add the team comparison column, then groupby by both and count unique players. 

```{code-cell} ipython3

new_team = lambda row: labels[row['TEAM_ID_2018']==row['TEAM_ID_2019']]
df1819_conf['team_1819']= df1819_conf.apply(new_team,axis=1)
df1819_conf.groupby(['conference_1819','team_1819'])['PLAYER_ID'].apply(pd.unique).apply(len)
```

This is good, we could read the answer from here.  It's good practice, though, to be able to pull that value out programmatically. 

```{code-cell} ipython3
player_counts_1819_team =  df1819_conf.groupby(['conference_1819','team_1819'])['PLAYER_ID'].apply(pd.unique).apply(len)
player_counts_1819_team.idxmax()
```

This tells us that the largest number of players stayed on the same team (and therefore same conference).  We're not interested inthis thoug, we're itnerested in those that changed teams, so we can drop the `(same,same)` value and then do this again. 

```{code-cell} ipython3
player_counts_1819_team.drop(('same','same')).idxmax()
```

This tells us that more players changed teams within the same conference than changed teams and conferences. We can compare the two directly:

```{code-cell} ipython3
player_counts_1819_team['new','new'], player_counts_1819_team['same','new']
```

Again 135 is more than 119.  

We can also make this a little neater to print it as a DataFrame.  If we use `reset_index` it will make a DataFrame, but the count column will still be named `PLAYER_ID` so we can rename it. 

```{code-cell} ipython3
player_counts_1819_team.reset_index().rename(columns={'PLAYER_ID':'num_players'})
```

All in all, this gives us a good answer that we can get with data and display answers and this is one way that using multiple data sources can help answer richer questions. 

```{code-cell} ipython3
conn.close()
```


## Questions

### do the level 3 attempts have a due date?

End of the semester basically is it. 

### how long is assignment 5?

It can be a little long, web scraping is relatively open-ended. 


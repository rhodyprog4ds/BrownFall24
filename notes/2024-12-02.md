---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.16.4
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

# NN

````{note}
Will fill in explanation later
````

```{code-cell} ipython3
from scipy.special import expit
from sklearn.datasets import make_classification
from sklearn.neural_network import MLPClassifier
from sklearn import svm
import pandas as pd
import numpy as np


from sklearn import datasets
import matplotlib.pyplot as plt
from sklearn import model_selection

from sklearn.model_selection import train_test_split

import seaborn as sns
sns.set_theme(palette='colorblind')
```

```{code-cell} ipython3
digits = datasets.load_digits()
digits_X = digits.data
digits_y = digits.target
X_train, X_test, y_train, y_test = model_selection.train_test_split(digits_X,digits_y)
```

```{code-cell} ipython3
digits.images[0]
```

```{code-cell} ipython3
mlp = MLPClassifier(
  hidden_layer_sizes=(16),
  max_iter=300,
  solver="lbfgs",
  verbose=10,
  random_state=1,
  learning_rate_init=0.1,
)
```

```{code-cell} ipython3
mlp.fit(X_train, y_train).score(X_test,y_test)
```

```{code-cell} ipython3
svm_clf = svm.SVC(gamma=0.001)
svm_clf.fit(X_train, y_train)
svm_clf.score(X_test,y_test)
```

```{code-cell} ipython3
svm_clf.support_vectors_.shape
```

```{code-cell} ipython3
np.prod(list(svm_clf.support_vectors_.shape))
```

```{code-cell} ipython3
np.sum([np.prod(list(c.shape)) for c in mlp.coefs_])
```

```{code-cell} ipython3
[list(c.shape) for c in mlp.coefs_]
```

```{code-cell} ipython3
X, y = make_classification(n_samples=100, random_state=1,n_features=2,n_redundant=0)
X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y,
             random_state=1)
sns.scatterplot(x=X[:,0],y=X[:,1],hue=y)
```

```{code-cell} ipython3
clf = MLPClassifier(
 hidden_layer_sizes=(1), # 1 hidden layer, 1 aritficial neuron
 max_iter=100, # maximum 100 interations in optimization
 alpha=1e-4, # regularization
 solver="lbfgs", #optimization algorithm  
 verbose=10, # how much detail to print
 activation= 'identity' # how to transform the hidden layer beofore passing it to the next layer
)
clf.fit(X_train, y_train)

clf.score(X_test, y_test)
```

```{code-cell} ipython3
clf.activation
```

```{code-cell} ipython3
clf.out_activation_
```

```{code-cell} ipython3
x_logistic = np.linspace(-10,10,100)
y_logistic = expit(x_logistic)
plt.plot(x_logistic,y_logistic)
```

```{code-cell} ipython3
clf.coefs_
```

```{code-cell} ipython3
clf.intercepts_
```

```{code-cell} ipython3
pt = np.array([-1,2])
```

```{code-cell} ipython3
np.matmul(pt,clf.coefs_[0]) + clf.intercepts_[0]
```

```{code-cell} ipython3
expit((np.matmul(pt,clf.coefs_[0]) + clf.intercepts_[0])*clf.coefs_[1] + clf.intercepts_[1])
```

```{code-cell} ipython3
clf.predict_proba([pt])
```

```{code-cell} ipython3
def aritificial_neuron_template(activation,weights,bias,inputs):
    '''
    simple artificial neuron

    Parameters
    ----------
    activation : function
    activation function of the neuron
    weights : numpy aray
    wights for summing inputs one per input
    bias: numpy array
    bias term added to the weighted sum
    inputs : numpy array
    input to the neuron, must be same size as weights

    '''
    return activation(np.matmul(inputs,weights) +bias)

# two common activation functions
identity_activation = lambda x: x
logistic_activation = lambda x: expit(x)
```

```{code-cell} ipython3
hidden_neuron = lambda x: aritificial_neuron_template(identity_activation,clf.coefs_[0],
                                                      clf.intercepts_[0],x)
output_neuron = lambda h: aritificial_neuron_template(expit,clf.coefs_[1],clf.intercepts_[1],h)

output_neuron(hidden_neuron(pt))
```

```{code-cell} ipython3
X, y = make_classification(n_samples=200, random_state=1,n_features=4,n_redundant=0,n_informative=4)
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,
                          random_state=5)
pt_4d =np.asarray([[-1,-2,2,-1],[1.5,0,.5,1]])
clf_4d = MLPClassifier(
  hidden_layer_sizes=(1),
  max_iter=5000,
  alpha=1e-4,
  solver="lbfgs",
  verbose=10,
  activation= 'identity'
)

clf_4d.fit(X_train, y_train)
clf_4d.score(X_test, y_test)
```

```{code-cell} ipython3
hidden_neuron_4d = lambda x: aritificial_neuron_template(identity_activation,
                             clf_4d.coefs_[0],clf_4d.intercepts_[0],x)
output_neuron_4d = lambda x: aritificial_neuron_template(logistic_activation,
                             clf_4d.coefs_[1],clf_4d.intercepts_[1],x)


output_neuron_4d(hidden_neuron_4d(pt_4d))
```

```{code-cell} ipython3
clf_4d.predict_proba(pt_4d)
```

```{code-cell} ipython3
df = pd.DataFrame(X,columns=['x0','x1','x2','x3'])
df['y'] = y
sns.pairplot(df,hue='y')
```

```{code-cell} ipython3

```
